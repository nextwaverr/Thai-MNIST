{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ThaiMNIST Example Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import extract_images, extract_labels\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trains a simple convnet on the MNIST dataset\n",
    "Gets to 99.26% test accuracy after 10 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "20 seconds per epoch on a GTX 1060 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset\\number\\\\train-images-idx3-ubyte.gz\n",
      "Extracting dataset\\number\\\\train-labels-idx1-ubyte.gz\n",
      "Extracting dataset\\number\\\\test-images-idx3-ubyte.gz\n",
      "Extracting dataset\\number\\\\test-labels-idx1-ubyte.gz\n",
      "x_train shape: (284977, 28, 28, 1)\n",
      "284977 train samples\n",
      "31659 test samples\n",
      "Train on 284977 samples, validate on 31659 samples\n",
      "Epoch 1/10\n",
      "284977/284977 [==============================] - 29s 102us/step - loss: 0.1764 - acc: 0.9437 - val_loss: 0.0353 - val_acc: 0.9893\n",
      "Epoch 2/10\n",
      "284977/284977 [==============================] - 28s 97us/step - loss: 0.0664 - acc: 0.9793 - val_loss: 0.0280 - val_acc: 0.9915 0s - loss: 0.0665\n",
      "Epoch 3/10\n",
      "284977/284977 [==============================] - 28s 98us/step - loss: 0.0503 - acc: 0.9841 - val_loss: 0.0231 - val_acc: 0.9925\n",
      "Epoch 4/10\n",
      "284977/284977 [==============================] - 28s 98us/step - loss: 0.0442 - acc: 0.9865 - val_loss: 0.0218 - val_acc: 0.9934\n",
      "Epoch 5/10\n",
      "284977/284977 [==============================] - 29s 103us/step - loss: 0.0390 - acc: 0.9878 - val_loss: 0.0202 - val_acc: 0.9940\n",
      "Epoch 6/10\n",
      "284977/284977 [==============================] - 29s 103us/step - loss: 0.0359 - acc: 0.9890 - val_loss: 0.0216 - val_acc: 0.9935\n",
      "Epoch 7/10\n",
      "284977/284977 [==============================] - 30s 104us/step - loss: 0.0323 - acc: 0.9899 - val_loss: 0.0210 - val_acc: 0.9938\n",
      "Epoch 8/10\n",
      "284977/284977 [==============================] - 29s 101us/step - loss: 0.0312 - acc: 0.9904 - val_loss: 0.0224 - val_acc: 0.9940\n",
      "Epoch 9/10\n",
      "284977/284977 [==============================] - 30s 106us/step - loss: 0.0295 - acc: 0.9908 - val_loss: 0.0204 - val_acc: 0.9944\n",
      "Epoch 10/10\n",
      "284977/284977 [==============================] - 28s 100us/step - loss: 0.0284 - acc: 0.9910 - val_loss: 0.0198 - val_acc: 0.9946\n",
      "Test loss: 0.019791452670065973\n",
      "Test accuracy: 0.9945671057203322\n"
     ]
    }
   ],
   "source": [
    "datasetpath = r'dataset\\number\\\\' # Change to your onw dataset\n",
    "\n",
    "with open(datasetpath + 'train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    x_train = extract_images(f)\n",
    "with open(datasetpath + 'train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    y_train = extract_labels(f)\n",
    "with open(datasetpath + 'test-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    x_test = extract_images(f)\n",
    "with open(datasetpath + 'test-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    y_test = extract_labels(f)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10 # default 10 if you train alphabet class change to 26\n",
    "epochs = 10 \n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/thaimnist.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = load_model('model/thaimnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape (1, 28, 28, 1)\n",
      "One-hot Prediction [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Label Prediction = 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "img_path = r'image\\number\\158.png' #Change Your own  image\n",
    "image = cv2.imread(img_path,0)\n",
    "pil_im = Image.open(img_path, 'r')\n",
    "image = image.reshape(1,28,28,1)\n",
    "\n",
    "print('Image Shape ' + str(image.shape))\n",
    "num =  model.predict(image)\n",
    "print('One-hot Prediction ' + str(num[0]))\n",
    "label = np.where(num[0] == 1)\n",
    "imshow(np.asarray(pil_im))\n",
    "print('Label Prediction = ' + str(label[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
